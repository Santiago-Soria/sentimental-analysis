{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2275330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Librerías cargadas!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from time import time\n",
    "\n",
    "# --- Módulos de Scikit-learn ---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# --- Módulos propios ---\n",
    "# Importamos la función de normalización del archivo normalization_functions\n",
    "from normalization_functions import pipeline_a_normalize\n",
    "\n",
    "# --- Configuración ---\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "print(\"¡Librerías cargadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36d36d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento cargados: 24169 opiniones.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    El mejor también en el lockdown También ahora, abiertos solo con comida para llevar y a domicilio es el mejór de lo mejór: mismo sabor, comida cal...\n",
       "1    Vacaciones con mi esposo Desde que llegamos al hotel el personal a estado muy atento con nosotros por lo cual estamos muy contentos y con ganas de...\n",
       "2    Super Bowl Excelente servicio y ponen el súper tazón en todas partes, muy recomendable. La comida es deliciosa, el servicio es excelente, el perso...\n",
       "3    Rico y abundante Excelente los desayunos muy abundantes gran variedad y combos precios muy accesibles y las malteadas bastante buenas en cuanto al...\n",
       "4    Tratamiento de spa Tuvimos un masaje de 80 minutos por fin y parejas y Katy, manicura y pedicura por Lupita y Jane. Todos eran excelentes en lo qu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Carga de Datos ---\n",
    "# Usamos los archivos que generaste de la Fase 0\n",
    "\n",
    "# Ruta relativa desde 'src/' a 'data/processed/train.csv'\n",
    "TRAIN_PATH = \"../data/processed/train.csv\"\n",
    "\n",
    "# Cargamos solo los datos de ENTRENAMIENTO\n",
    "try:\n",
    "    df_train = pd.read_csv(TRAIN_PATH)\n",
    "    df_train.dropna(subset=['text', 'Polarity'], inplace=True) # Asegurar que no hay nulos\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: No se encontró el archivo {TRAIN_PATH}\")\n",
    "    print(\"Asegúrate de haber ejecutado '0_split_data.py' primero.\")\n",
    "\n",
    "# Definimos X_train y y_train\n",
    "# ¡Nunca tocamos el archivo test.csv en esta fase!\n",
    "X_train = df_train['text']\n",
    "y_train = df_train['Polarity']\n",
    "\n",
    "print(f\"Datos de entrenamiento cargados: {len(X_train)} opiniones.\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab828a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Experimento 1: (Pipeline A + Binario + Naive Bayes)\n",
      "\n",
      "--- Resultados (Experimento 1) ---\n",
      "F1-Macro Promedio (5-folds): 0.2701 (+/- 0.0071)\n",
      "Tiempo de ejecución: 11.02 segundos\n",
      "\n",
      "¡Experimento 1 completado!\n"
     ]
    }
   ],
   "source": [
    "# --- Experimento 1: Pipeline A + Binario + Naive Bayes ---\n",
    "\n",
    "print(\"Iniciando Experimento 1: (Pipeline A + Binario + Naive Bayes)\")\n",
    "start_time = time()\n",
    "\n",
    "# 1. Definir el pipeline\n",
    "pipeline_nb_bin = Pipeline([\n",
    "    # Paso 1: Vectorizador (Representación)\n",
    "    # Usamos CountVectorizer con binary=True para la representación Binaria\n",
    "    # También aplicamos la normalización (tu función) directamente aquí\n",
    "    ('vectorizer', CountVectorizer(\n",
    "        preprocessor=pipeline_a_normalize,  # <-- Tu función de limpieza\n",
    "        binary=True                         # <-- Representación Binaria\n",
    "    )),\n",
    "    \n",
    "    # Paso 2: Modelo (Clasificador)\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# 2. Definir la estrategia de validación cruzada\n",
    "# Dividimos el set de entrenamiento en 5 folds (partes) [cite: 33]\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42) # Usamos 42 para reproducibilidad en la validación\n",
    "\n",
    "# 3. Definir la métrica de evaluación\n",
    "# Queremos calcular el F1-Macro [cite: 37, 43]\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 4. Ejecutar la validación cruzada\n",
    "# Esto entrena y evalúa el pipeline 5 veces, una por cada fold\n",
    "cv_results = cross_validate(\n",
    "    pipeline_nb_bin,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=kfold,\n",
    "    scoring={'f1_macro': f1_macro_scorer}\n",
    ")\n",
    "\n",
    "# 5. Calcular y mostrar resultados\n",
    "end_time = time()\n",
    "avg_f1 = cv_results['test_f1_macro'].mean()\n",
    "std_f1 = cv_results['test_f1_macro'].std()\n",
    "exec_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Resultados (Experimento 1) ---\")\n",
    "print(f\"F1-Macro Promedio (5-folds): {avg_f1:.4f} (+/- {std_f1:.4f})\")\n",
    "print(f\"Tiempo de ejecución: {exec_time:.2f} segundos\")\n",
    "\n",
    "# Guardamos este resultado para el reporte final\n",
    "results_log = [{\n",
    "    'pipeline': 'A',\n",
    "    'vectorizer': 'Binario',\n",
    "    'model': 'Naive Bayes',\n",
    "    'avg_f1_macro': avg_f1,\n",
    "    'std_f1_macro': std_f1\n",
    "}]\n",
    "\n",
    "print(\"\\n¡Experimento 1 completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33344690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Experimento 2: (Pipeline A + Binario + Logistic Regression)\n",
      "\n",
      "--- Resultados (Experimento 2) ---\n",
      "F1-Macro Promedio (5-folds): 0.4556 (+/- 0.0122)\n",
      "Tiempo de ejecución: 45.71 segundos\n",
      "\n",
      "¡Experimento 2 completado!\n"
     ]
    }
   ],
   "source": [
    "# --- Experimento 2: Pipeline A + Binario + Logistic Regression ---\n",
    "\n",
    "print(\"Iniciando Experimento 2: (Pipeline A + Binario + Logistic Regression)\")\n",
    "start_time = time()\n",
    "\n",
    "# 1. Definir el pipeline\n",
    "pipeline_lr_bin = Pipeline([\n",
    "    # Paso 1: Vectorizador (Binario)\n",
    "    ('vectorizer', CountVectorizer(\n",
    "        preprocessor=pipeline_a_normalize,\n",
    "        binary=True\n",
    "    )),\n",
    "    \n",
    "    # Paso 2: Modelo (Clasificador)\n",
    "    # ¡Cambiamos el clasificador!\n",
    "    ('classifier', LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000  # Aumentamos max_iter para asegurar que converja\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2. Definir la estrategia de validación cruzada (la misma de antes)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. Definir la métrica (la misma de antes)\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 4. Ejecutar la validación cruzada\n",
    "cv_results = cross_validate(\n",
    "    pipeline_lr_bin,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=kfold,\n",
    "    scoring={'f1_macro': f1_macro_scorer}\n",
    ")\n",
    "\n",
    "# 5. Calcular y mostrar resultados\n",
    "end_time = time()\n",
    "avg_f1 = cv_results['test_f1_macro'].mean()\n",
    "std_f1 = cv_results['test_f1_macro'].std()\n",
    "exec_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Resultados (Experimento 2) ---\")\n",
    "print(f\"F1-Macro Promedio (5-folds): {avg_f1:.4f} (+/- {std_f1:.4f})\")\n",
    "print(f\"Tiempo de ejecución: {exec_time:.2f} segundos\")\n",
    "\n",
    "# Guardamos este resultado\n",
    "results_log.append({\n",
    "    'pipeline': 'A',\n",
    "    'vectorizer': 'Binario',\n",
    "    'model': 'Logistic Regression',\n",
    "    'avg_f1_macro': avg_f1,\n",
    "    'std_f1_macro': std_f1\n",
    "})\n",
    "\n",
    "print(\"\\n¡Experimento 2 completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45168c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Experimento 3: (Pipeline A + Frecuencia + Naive Bayes)\n",
      "\n",
      "--- Resultados (Experimento 3) ---\n",
      "F1-Macro Promedio (5-folds): 0.3059 (+/- 0.0087)\n",
      "Tiempo de ejecución: 9.70 segundos\n",
      "\n",
      "¡Experimento 3 completado!\n"
     ]
    }
   ],
   "source": [
    "# --- Experimento 3: Pipeline A + Frecuencia + Naive Bayes ---\n",
    "\n",
    "print(\"Iniciando Experimento 3: (Pipeline A + Frecuencia + Naive Bayes)\")\n",
    "start_time = time()\n",
    "\n",
    "# 1. Definir el pipeline\n",
    "pipeline_nb_freq = Pipeline([\n",
    "    # Paso 1: Vectorizador (Representación)\n",
    "    # Es el mismo CountVectorizer, PERO sin 'binary=True'\n",
    "    ('vectorizer', CountVectorizer(\n",
    "        preprocessor=pipeline_a_normalize  # Tu función de limpieza\n",
    "    )),\n",
    "    \n",
    "    # Paso 2: Modelo (Clasificador)\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# 2. Definir la estrategia de validación cruzada\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. Definir la métrica\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 4. Ejecutar la validación cruzada\n",
    "cv_results = cross_validate(\n",
    "    pipeline_nb_freq,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=kfold,\n",
    "    scoring={'f1_macro': f1_macro_scorer}\n",
    ")\n",
    "\n",
    "# 5. Calcular y mostrar resultados\n",
    "end_time = time()\n",
    "avg_f1 = cv_results['test_f1_macro'].mean()\n",
    "std_f1 = cv_results['test_f1_macro'].std()\n",
    "exec_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Resultados (Experimento 3) ---\")\n",
    "print(f\"F1-Macro Promedio (5-folds): {avg_f1:.4f} (+/- {std_f1:.4f})\")\n",
    "print(f\"Tiempo de ejecución: {exec_time:.2f} segundos\")\n",
    "\n",
    "# Guardamos este resultado\n",
    "results_log.append({\n",
    "    'pipeline': 'A',\n",
    "    'vectorizer': 'Frecuencia',\n",
    "    'model': 'Naive Bayes',\n",
    "    'avg_f1_macro': avg_f1,\n",
    "    'std_f1_macro': std_f1\n",
    "})\n",
    "\n",
    "print(\"\\n¡Experimento 3 completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02fa1c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Experimento 4: (Pipeline A + Frecuencia + Logistic Regression)\n",
      "\n",
      "--- Resultados (Experimento 4) ---\n",
      "F1-Macro Promedio (5-folds): 0.4552 (+/- 0.0134)\n",
      "Tiempo de ejecución: 149.69 segundos\n",
      "\n",
      "¡Experimento 4 completado!\n"
     ]
    }
   ],
   "source": [
    "# --- Experimento 4: Pipeline A + Frecuencia + Logistic Regression ---\n",
    "\n",
    "print(\"Iniciando Experimento 4: (Pipeline A + Frecuencia + Logistic Regression)\")\n",
    "start_time = time()\n",
    "\n",
    "# 1. Definir el pipeline\n",
    "pipeline_lr_freq = Pipeline([\n",
    "    # Paso 1: Vectorizador (Frecuencia)\n",
    "    ('vectorizer', CountVectorizer(\n",
    "        preprocessor=pipeline_a_normalize\n",
    "    )),\n",
    "    \n",
    "    # Paso 2: Modelo (Clasificador)\n",
    "    ('classifier', LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2. Definir la estrategia de validación cruzada\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. Definir la métrica\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 4. Ejecutar la validación cruzada\n",
    "cv_results = cross_validate(\n",
    "    pipeline_lr_freq,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=kfold,\n",
    "    scoring={'f1_macro': f1_macro_scorer}\n",
    ")\n",
    "\n",
    "# 5. Calcular y mostrar resultados\n",
    "end_time = time()\n",
    "avg_f1 = cv_results['test_f1_macro'].mean()\n",
    "std_f1 = cv_results['test_f1_macro'].std()\n",
    "exec_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Resultados (Experimento 4) ---\")\n",
    "print(f\"F1-Macro Promedio (5-folds): {avg_f1:.4f} (+/- {std_f1:.4f})\")\n",
    "print(f\"Tiempo de ejecución: {exec_time:.2f} segundos\")\n",
    "\n",
    "# Guardamos este resultado\n",
    "results_log.append({\n",
    "    'pipeline': 'A',\n",
    "    'vectorizer': 'Frecuencia',\n",
    "    'model': 'Logistic Regression',\n",
    "    'avg_f1_macro': avg_f1,\n",
    "    'std_f1_macro': std_f1\n",
    "})\n",
    "\n",
    "print(\"\\n¡Experimento 4 completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "420fd9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Experimento 5: (Pipeline A + TF-IDF + Naive Bayes)\n",
      "\n",
      "--- Resultados (Experimento 5) ---\n",
      "F1-Macro Promedio (5-folds): 0.1636 (+/- 0.0010)\n",
      "Tiempo de ejecución: 9.52 segundos\n",
      "\n",
      "¡Experimento 5 completado!\n"
     ]
    }
   ],
   "source": [
    "# --- Experimento 5: Pipeline A + TF-IDF + Naive Bayes ---\n",
    "\n",
    "print(\"Iniciando Experimento 5: (Pipeline A + TF-IDF + Naive Bayes)\")\n",
    "start_time = time()\n",
    "\n",
    "# 1. Definir el pipeline\n",
    "pipeline_nb_tfidf = Pipeline([\n",
    "    # Paso 1: Vectorizador (Representación)\n",
    "    # ¡Cambiamos a TfidfVectorizer!\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        preprocessor=pipeline_a_normalize  # Tu función de limpieza\n",
    "    )),\n",
    "    \n",
    "    # Paso 2: Modelo (Clasificador)\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# 2. Definir la estrategia de validación cruzada\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. Definir la métrica\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 4. Ejecutar la validación cruzada\n",
    "cv_results = cross_validate(\n",
    "    pipeline_nb_tfidf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=kfold,\n",
    "    scoring={'f1_macro': f1_macro_scorer}\n",
    ")\n",
    "\n",
    "# 5. Calcular y mostrar resultados\n",
    "end_time = time()\n",
    "avg_f1 = cv_results['test_f1_macro'].mean()\n",
    "std_f1 = cv_results['test_f1_macro'].std()\n",
    "exec_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Resultados (Experimento 5) ---\")\n",
    "print(f\"F1-Macro Promedio (5-folds): {avg_f1:.4f} (+/- {std_f1:.4f})\")\n",
    "print(f\"Tiempo de ejecución: {exec_time:.2f} segundos\")\n",
    "\n",
    "# Guardamos este resultado\n",
    "results_log.append({\n",
    "    'pipeline': 'A',\n",
    "    'vectorizer': 'TF-IDF',\n",
    "    'model': 'Naive Bayes',\n",
    "    'avg_f1_macro': avg_f1,\n",
    "    'std_f1_macro': std_f1\n",
    "})\n",
    "\n",
    "print(\"\\n¡Experimento 5 completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f97f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Experimento 6: (Pipeline A + TF-IDF + Logistic Regression)\n",
      "\n",
      "--- Resultados (Experimento 6) ---\n",
      "F1-Macro Promedio (5-folds): 0.4025 (+/- 0.0034)\n",
      "Tiempo de ejecución: 25.17 segundos\n",
      "\n",
      "¡Experimento 6 completado!\n"
     ]
    }
   ],
   "source": [
    "# --- Experimento 6: Pipeline A + TF-IDF + Logistic Regression ---\n",
    "\n",
    "print(\"Iniciando Experimento 6: (Pipeline A + TF-IDF + Logistic Regression)\")\n",
    "start_time = time()\n",
    "\n",
    "# 1. Definir el pipeline\n",
    "pipeline_lr_tfidf = Pipeline([\n",
    "    # Paso 1: Vectorizador (TF-IDF)\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        preprocessor=pipeline_a_normalize\n",
    "    )),\n",
    "    \n",
    "    # Paso 2: Modelo (Clasificador)\n",
    "    # ¡Cambiamos al clasificador LogisticRegression!\n",
    "    ('classifier', LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2. Definir la estrategia de validación cruzada\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 3. Definir la métrica\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 4. Ejecutar la validación cruzada\n",
    "cv_results = cross_validate(\n",
    "    pipeline_lr_tfidf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=kfold,\n",
    "    scoring={'f1_macro': f1_macro_scorer}\n",
    ")\n",
    "\n",
    "# 5. Calcular y mostrar resultados\n",
    "end_time = time()\n",
    "avg_f1 = cv_results['test_f1_macro'].mean()\n",
    "std_f1 = cv_results['test_f1_macro'].std()\n",
    "exec_time = end_time - start_time\n",
    "\n",
    "print(\"\\n--- Resultados (Experimento 6) ---\")\n",
    "print(f\"F1-Macro Promedio (5-folds): {avg_f1:.4f} (+/- {std_f1:.4f})\")\n",
    "print(f\"Tiempo de ejecución: {exec_time:.2f} segundos\")\n",
    "\n",
    "# Guardamos este último resultado\n",
    "results_log.append({\n",
    "    'pipeline': 'A',\n",
    "    'vectorizer': 'TF-IDF',\n",
    "    'model': 'Logistic Regression',\n",
    "    'avg_f1_macro': avg_f1,\n",
    "    'std_f1_macro': std_f1\n",
    "})\n",
    "\n",
    "print(\"\\n¡Experimento 6 completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c20f7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumen de Resultados (Pipeline A) ---\n",
      "\n",
      "¡Éxito! Resultados guardados en: ../results/fase_1_pipeline_A.csv\n",
      "\n",
      "Resultados finales:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model</th>\n",
       "      <th>avg_f1_macro</th>\n",
       "      <th>std_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Binario</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.455560</td>\n",
       "      <td>0.012169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Frecuencia</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.455174</td>\n",
       "      <td>0.013371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.402485</td>\n",
       "      <td>0.003411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Frecuencia</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.305907</td>\n",
       "      <td>0.008735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Binario</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.270102</td>\n",
       "      <td>0.007121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.163595</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pipeline  vectorizer                model  avg_f1_macro  std_f1_macro\n",
       "1        A     Binario  Logistic Regression      0.455560      0.012169\n",
       "3        A  Frecuencia  Logistic Regression      0.455174      0.013371\n",
       "5        A      TF-IDF  Logistic Regression      0.402485      0.003411\n",
       "2        A  Frecuencia          Naive Bayes      0.305907      0.008735\n",
       "0        A     Binario          Naive Bayes      0.270102      0.007121\n",
       "4        A      TF-IDF          Naive Bayes      0.163595      0.001005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Fin de la Fase 1: Guardar Resultados ---\n",
    "\n",
    "print(\"--- Resumen de Resultados (Pipeline A) ---\")\n",
    "\n",
    "# 1. Convertir el log de resultados a un DataFrame\n",
    "df_results = pd.DataFrame(results_log)\n",
    "df_results.sort_values(by='avg_f1_macro', ascending=False, inplace=True)\n",
    "\n",
    "# 2. Definir la ruta de guardado\n",
    "# Guardaremos esto en la carpeta 'results/'\n",
    "RESULTS_PATH = \"../results/fase_1_pipeline_A.csv\"\n",
    "\n",
    "# 3. Guardar el DataFrame en un archivo CSV\n",
    "try:\n",
    "    df_results.to_csv(RESULTS_PATH, index=False, encoding='utf-8')\n",
    "    print(f\"\\n¡Éxito! Resultados guardados en: {RESULTS_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar los resultados: {e}\")\n",
    "\n",
    "# 4. Mostrar el DataFrame final en el notebook\n",
    "print(\"\\nResultados finales:\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42f7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
