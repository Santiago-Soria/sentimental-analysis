{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aba004d",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f27f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recurso 'stopwords' de NLTK ya está descargado.\n",
      "Cargadas 313 stopwords en español.\n",
      "Modelo 'es_core_news_sm' de spaCy cargado.\n",
      "¡Librerías de Fase 3 (SVM) cargadas!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from time import time\n",
    "\n",
    "# --- Módulos de Scikit-learn ---\n",
    "from sklearn.svm import LinearSVC  # ¡Tu modelo! (Más rápido que SVC para texto)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# --- Módulos propios (¡Los ganadores!) ---\n",
    "# 1. Normalización Ganadora\n",
    "from normalization_functions import pipeline_d_normalize\n",
    "# 2. Representación Ganadora (Binary + Lexicons)\n",
    "from lexicon_functions import get_augmented_features\n",
    "\n",
    "# --- Configuración ---\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"¡Librerías de Fase 3 (SVM) cargadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae76ec",
   "metadata": {},
   "source": [
    "### Carga y PRE-Normalización de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce8d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Fase 3: SVM + GridSearchCV\n",
      "Aplicando 'pipeline_d_normalize' a 24169 opiniones...\n",
      "Datos normalizados listos. (Tiempo: 2.36s)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Configuración de Rutas ---\n",
    "TRAIN_PATH = os.path.join(\"..\", \"data\", \"processed\", \"train.csv\")\n",
    "# ¡Tu archivo de resultados!\n",
    "RESULTS_PATH = os.path.join(\"..\", \"results\", \"fase_3_svm_results.csv\")\n",
    "\n",
    "os.makedirs(os.path.dirname(RESULTS_PATH), exist_ok=True)\n",
    "\n",
    "# --- 2. Cargar Datos ---\n",
    "print(\"Iniciando Fase 3: SVM + GridSearchCV\")\n",
    "try:\n",
    "    df_train = pd.read_csv(TRAIN_PATH)\n",
    "    df_train.dropna(subset=['text', 'Polarity'], inplace=True)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: No se encontró el archivo {TRAIN_PATH}\")\n",
    "    # Si da error, detén la ejecución (en un notebook, esto es simbólico)\n",
    "    raise\n",
    "\n",
    "# --- 3. Aplicar Normalización GANADORA (Paso 1) ---\n",
    "print(f\"Aplicando 'pipeline_d_normalize' a {len(df_train)} opiniones...\")\n",
    "start_norm = time()\n",
    "\n",
    "X_train_normalized = df_train['text'].apply(pipeline_d_normalize)\n",
    "y_train = df_train['Polarity']\n",
    "\n",
    "end_norm = time()\n",
    "print(f\"Datos normalizados listos. (Tiempo: {end_norm - start_norm:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72234ac0",
   "metadata": {},
   "source": [
    "### Definir Pipeline y Rejilla de Búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb01c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV (SVM) configurado.\n",
      "Probando 3 valores de 'C' con 5-fold CV...\n",
      "Total de entrenamientos:  15\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Definir Pipeline de Modelo ---\n",
    "# Pipeline:\n",
    "# 1. 'features': La representación ganadora (Binary + Lexicons)\n",
    "# 2. 'classifier': Tu modelo SVM\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('features', get_augmented_features()), #\n",
    "    ('classifier', LinearSVC(random_state=42, max_iter=3000)) # Modelo\n",
    "])\n",
    "\n",
    "# --- 5. Definir Rejilla de Hiperparámetros ---\n",
    "# 'classifier__C' se refiere al parámetro 'C' del paso 'classifier' (LinearSVC)\n",
    "# 'C' es el parámetro de regularización de SVM.\n",
    "# Valores bajos (0.1) -> Más regularización (modelo más simple)\n",
    "# Valores altos (10) -> Menos regularización (modelo más complejo)\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# --- 6. Configurar GridSearchCV ---\n",
    "# verbose=3 para que se vea el progreso\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                # 5 folds\n",
    "    scoring='f1_macro',  # Métrica\n",
    "    n_jobs=-1,           # Usar todos los núcleos de CPU\n",
    "    verbose=3            \n",
    ")\n",
    "\n",
    "print(\"GridSearchCV (SVM) configurado.\")\n",
    "print(f\"Probando {len(param_grid['classifier__C'])} valores de 'C' con 5-fold CV...\")\n",
    "print(\"Total de entrenamientos: \", len(param_grid['classifier__C']) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76324da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ¡INICIANDO GRIDSEARCHCV (SVM)! ---\n",
      "Alimentando el modelo con 24169 opiniones normalizadas.\n",
      "Esto puede tardar varios minutos (o más)... ten paciencia.\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "--- [lexicon_utils] Cargando recursos lingüísticos ---\n",
      "\n",
      "--- ¡GridSearchCV (SVM) completado! ---\n",
      "Tiempo total de búsqueda: 1.66 minutos\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Ejecutar GridSearchCV ---\n",
    "\n",
    "print(\"--- ¡INICIANDO GRIDSEARCHCV (SVM)! ---\")\n",
    "print(f\"Alimentando el modelo con {len(X_train_normalized)} opiniones normalizadas.\")\n",
    "print(\"Esto puede tardar varios minutos (o más)... ten paciencia.\")\n",
    "\n",
    "start_grid = time()\n",
    "\n",
    "try:\n",
    "    # Aquí es donde se ejecuta el trabajo pesado:\n",
    "    # Probará C=0.1 (con 5 folds), C=1 (con 5 folds) y C=10 (con 5 folds)\n",
    "    grid_search.fit(X_train_normalized, y_train)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n¡Error durante el entrenamiento de GridSearchCV! {e}\")\n",
    "    # Si hay un error, lo saltamos para poder seguir\n",
    "    pass\n",
    "\n",
    "end_grid = time()\n",
    "print(f\"\\n--- ¡GridSearchCV (SVM) completado! ---\")\n",
    "print(f\"Tiempo total de búsqueda: {(end_grid - start_grid) / 60:.2f} minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a075cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados de la Fase 3 (SVM) ---\n",
      "Mejor F1-Macro (promedio de CV): 0.4457\n",
      "Mejores Hiperparámetros encontrados: {'classifier__C': 0.1}\n",
      "\n",
      "Resultados de la Fase 3 guardados en: ..\\results\\fase_3_svm_results.csv\n",
      "\n",
      "Detalle de la búsqueda (GridSearchCV):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.113360</td>\n",
       "      <td>0.389653</td>\n",
       "      <td>0.813006</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'classifier__C': 0.1}</td>\n",
       "      <td>0.441937</td>\n",
       "      <td>0.440306</td>\n",
       "      <td>0.478936</td>\n",
       "      <td>0.422730</td>\n",
       "      <td>0.444540</td>\n",
       "      <td>0.445690</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.194662</td>\n",
       "      <td>4.389018</td>\n",
       "      <td>0.667039</td>\n",
       "      <td>0.071004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'classifier__C': 1}</td>\n",
       "      <td>0.429158</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.457384</td>\n",
       "      <td>0.402512</td>\n",
       "      <td>0.430572</td>\n",
       "      <td>0.427720</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.730683</td>\n",
       "      <td>9.280642</td>\n",
       "      <td>0.426699</td>\n",
       "      <td>0.104072</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'classifier__C': 10}</td>\n",
       "      <td>0.410583</td>\n",
       "      <td>0.412450</td>\n",
       "      <td>0.431974</td>\n",
       "      <td>0.393553</td>\n",
       "      <td>0.413986</td>\n",
       "      <td>0.412509</td>\n",
       "      <td>0.012199</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      11.113360      0.389653         0.813006        0.043105   \n",
       "1      40.194662      4.389018         0.667039        0.071004   \n",
       "2      59.730683      9.280642         0.426699        0.104072   \n",
       "\n",
       "   param_classifier__C                  params  split0_test_score  \\\n",
       "0                  0.1  {'classifier__C': 0.1}           0.441937   \n",
       "1                  1.0    {'classifier__C': 1}           0.429158   \n",
       "2                 10.0   {'classifier__C': 10}           0.410583   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.440306           0.478936           0.422730           0.444540   \n",
       "1           0.418976           0.457384           0.402512           0.430572   \n",
       "2           0.412450           0.431974           0.393553           0.413986   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.445690        0.018313                1  \n",
       "1         0.427720        0.017900                2  \n",
       "2         0.412509        0.012199                3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 8. Guardar y Reportar Resultados ---\n",
    "\n",
    "print(\"--- Resultados de la Fase 3 (SVM) ---\")\n",
    "\n",
    "try:\n",
    "    # Extraer los mejores resultados del objeto grid_search\n",
    "    best_score = grid_search.best_score_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(f\"Mejor F1-Macro (promedio de CV): {best_score:.4f}\")\n",
    "    print(f\"Mejores Hiperparámetros encontrados: {best_params}\")\n",
    "\n",
    "    # Guardar los resultados en el archivo CSV que definimos en la Celda 2\n",
    "    results_df = pd.DataFrame({\n",
    "        \"model\": \"LinearSVC (SVM)\",\n",
    "        \"pipeline_base\": \"D (Negación) + FeatureUnion (Binary + Lexicons)\",\n",
    "        \"best_avg_f1_macro\": [best_score],\n",
    "        \"best_params\": [str(best_params)] # Guardar como string\n",
    "    })\n",
    "\n",
    "    results_df.to_csv(RESULTS_PATH, index=False)\n",
    "    print(f\"\\nResultados de la Fase 3 guardados en: {RESULTS_PATH}\")\n",
    "\n",
    "    # También muestra todos los resultados de la búsqueda\n",
    "    print(\"\\nDetalle de la búsqueda (GridSearchCV):\")\n",
    "    display(pd.DataFrame(grid_search.cv_results_))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n¡Error al guardar resultados! {e}\")\n",
    "    print(\"Verifica si el 'grid_search.fit()' de la celda anterior se completó correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
